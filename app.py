# app.py
import streamlit as st
from dotenv import load_dotenv
from modules.ui import display_ui, display_results
from modules.rag import build_rag_pipeline
from modules.llm import get_llm_responses

def main():
    """
    ë©”ì¸ í•¨ìˆ˜: Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    """
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # UI í‘œì‹œ ë° ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    uploaded_file, question, selected_models = display_ui()

    # PDF íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    # st.session_stateë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ì— ì—…ë¡œë“œëœ íŒŒì¼ì¸ì§€ í™•ì¸
    if uploaded_file and st.session_state.get("uploaded_file_name") != uploaded_file.name:
        with st.spinner("PDFë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.vector_store = build_rag_pipeline(uploaded_file)
            st.session_state.uploaded_file_name = uploaded_file.name # íŒŒì¼ ì´ë¦„ ì €ì¥
            st.session_state.messages = [] # ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        st.success("PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ì§ˆë¬¸ì´ ìˆê³ , ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìœ¼ë©°, ë²¡í„° ì €ì¥ì†Œê°€ ì¤€ë¹„ëœ ê²½ìš°
    if question and any(selected_models.values()) and st.session_state.vector_store:
        # ì‚¬ìš©ì ì§ˆë¬¸ì„ ë©”ì‹œì§€ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": question})

        # LLM ì‘ë‹µ ë°›ì•„ì˜¤ê¸°
        with st.spinner("LLM ëª¨ë¸ë“¤ì˜ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            active_models = {name: selected for name, selected in selected_models.items() if selected}
            responses = get_llm_responses(
                question=question,
                vector_store=st.session_state.vector_store,
                selected_models=active_models
            )
        
        # LLM ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": responses})

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    if st.session_state.messages:
        for message in st.session_state.messages:
            # roleì— ë”°ë¼ ì•„ì´ì½˜ ë¶„ê¸°
            avatar = "ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"
            with st.chat_message(message["role"], avatar=avatar):
                if isinstance(message["content"], dict): # LLM ì‘ë‹µì¸ ê²½ìš°
                     display_results(message["content"])
                else: # ì‚¬ìš©ì ì§ˆë¬¸ì¸ ê²½ìš°
                    st.markdown(message["content"])


if __name__ == "__main__":
    main()